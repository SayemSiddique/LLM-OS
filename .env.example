# Environment Variables for LLM-OS
# Copy this file to .env.local and fill in your actual values

# Firebase Configuration (for real-time features and user management)
NEXT_PUBLIC_FIREBASE_API_KEY=your_firebase_api_key_here
NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN=your_project.firebaseapp.com
NEXT_PUBLIC_FIREBASE_PROJECT_ID=your_project_id
NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET=your_project.appspot.com
NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID=your_messaging_sender_id
NEXT_PUBLIC_FIREBASE_APP_ID=your_app_id

# OpenAI API Key (required for LLM functionality)
OPENAI_API_KEY=your_openai_api_key_here

# Optional: OpenAI Organization ID (if applicable)
OPENAI_ORG_ID=your_org_id_here

# Optional: Custom API Base URL (for OpenAI-compatible endpoints)
OPENAI_API_BASE=https://api.openai.com/v1

# Development/Production mode
NODE_ENV=development

# Optional: Analytics and monitoring
NEXT_PUBLIC_ANALYTICS_ID=your_analytics_id
NEXT_PUBLIC_SENTRY_DSN=your_sentry_dsn

# Optional: Rate limiting and security
RATE_LIMIT_MAX=100
RATE_LIMIT_WINDOW=3600
JWT_SECRET=your_jwt_secret_here

# Optional: Vector database for embeddings (if using advanced features)
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENVIRONMENT=your_pinecone_environment
PINECONE_INDEX_NAME=llm-os-embeddings
